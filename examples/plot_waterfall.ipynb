{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce378089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import dascore as dc\n",
    "\n",
    "from das_anomaly.settings import SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path  = SETTINGS.RESULTS_PATH\n",
    "\n",
    "waterfall_path = \"path/for/waterfall/plots\"\n",
    "waterfall_dir = Path(waterfall_path)\n",
    "waterfall_dir.mkdir(parents=True, exist_ok=True)  # creates it if it doesn't exist\n",
    "\n",
    "data_path = SETTINGS.DATA_PATH\n",
    "data_unit = SETTINGS.DATA_UNIT\n",
    "\n",
    "min_freq = SETTINGS.MIN_FREQ \n",
    "max_freq = SETTINGS.MAX_FREQ \n",
    "step_multiple = SETTINGS.STEP_MULTIPLE \n",
    "start_channel = SETTINGS.START_CHANNEL \n",
    "end_channel = SETTINGS.END_CHANNEL \n",
    "time_window = SETTINGS.TIME_WINDOW\n",
    "time_overlap = SETTINGS.TIME_OVERLAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one path per line\n",
    "s = pd.read_csv(txt_path, header=None, names=[\"path\"], dtype=str)\n",
    "\n",
    "# Extract timestamps\n",
    "ts = s[\"path\"].str.extract(\n",
    "    r'(?P<time_min>\\d{4}_\\d{2}_\\d{2}T\\d{2}_\\d{2}_\\d{2})__'\n",
    "    r'(?P<time_max>\\d{4}_\\d{2}_\\d{2}T\\d{2}_\\d{2}_\\d{2})'\n",
    ")\n",
    "\n",
    "# Build DataFrame with 1-based row numbers\n",
    "df = pd.concat([s.index.to_series().add(1).rename(\"rows\"), ts], axis=1)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _distance_slice(patch):\n",
    "    \"\"\"Convert channel range to distance range.\"\"\"\n",
    "    start = patch.coords[\"distance\"][start_channel]\n",
    "    end = patch.coords[\"distance\"][end_channel]\n",
    "    return (start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = dc.spool(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53799e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_time = True\n",
    "\n",
    "for row in df.itertuples(index=True):  # index=False if you don't need the index\n",
    "    i = row.Index          # row number (DataFrame index)\n",
    "    t1 = pd.to_datetime(row.time_min, format=\"%Y_%m_%dT%H_%M_%S\")       \n",
    "    t2 = pd.to_datetime(row.time_max, format=\"%Y_%m_%dT%H_%M_%S\")\n",
    "    \n",
    "    if i>1:\n",
    "         break\n",
    "\n",
    "    if select_time:\n",
    "        sub_sp_time = sp.select(time=(t1, t2))\n",
    "        sub_sp_time_distance = sub_sp_time.select(distance=(_distance_slice(sub_sp_time[0])))\n",
    "        sub_sp = sub_sp_time_distance\n",
    "    else:\n",
    "        sub_sp_distance = sp.select(distance=(_distance_slice(sp[0]))) \n",
    "        sub_sp = sub_sp_distance\n",
    "    # chunk into windowed sub-patches\n",
    "    sub_sp_chunked = sub_sp.sort(\"time\").chunk(\n",
    "        time=time_window, keep_partial=True,\n",
    "    )\n",
    "    if len(sub_sp_chunked) == 0:\n",
    "        raise ValueError(\"No patch of DAS data found within data path: %s\")\n",
    "    # iterate over patches and perform preprocessing\n",
    "    for pa_num, patch in enumerate(sub_sp_chunked):\n",
    "        if data_unit == \"velocity\":\n",
    "                proc_patch = patch.velocity_to_strain_rate_edgeless(\n",
    "                    step_multiple=step_multiple\n",
    "                ).detrend(\"time\")\n",
    "        elif data_unit == \"strain_rate\":\n",
    "                proc_patch = patch.detrend(\"time\")\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Unsupported data_unit: {data_unit!r}. \"\n",
    "                \"Expected 'velocity' or 'strain_rate'.\"\n",
    "            )\n",
    "        ax = proc_patch.viz.waterfall(show=False, scale=(-2.5e-6,2.5e-6))\n",
    "        fig = ax.get_figure()          # or: fig = ax.figure\n",
    "        name = Path(s[\"path\"].iloc[i]).stem\n",
    "        fig.savefig(waterfall_dir / f\"{name}_{pa_num}.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dasanomaly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
