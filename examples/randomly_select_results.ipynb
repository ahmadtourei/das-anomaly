{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d929088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, re, shutil\n",
    "import csv\n",
    "import random, re, shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0859d24",
   "metadata": {},
   "source": [
    "# Randomly select anomalies and normal images separately to evaluate and pick an appropriate threshold for the detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [-346, -200, -100, 10, 100, 250, 350, 500, 600, 700, 800, 900, 1000, 1200, 1400, 1600, 1800, 2000, 5000, 8769]:\n",
    "    ROOT = Path(f\"/scratch/ahmad9/caserm/detect_mse_and_density/model1600/512.256.4/results_thresh_{threshold}/evaluate/\")\n",
    "    TXT_DIR = f\"/scratch/ahmad9/caserm/detect_mse_and_density/model1600/512.256.4/results_thresh_{threshold}\"  # directory containing many .txt files\n",
    "    OUT_DIR_ALL = f\"/scratch/ahmad9/caserm/detect_mse_and_density/model1600/512.256.4/results_thresh_{threshold}/evaluate/randomly_selected_all\"\n",
    "    OUT_DIR_ANOMALY = f\"/scratch/ahmad9/caserm/detect_mse_and_density/model1600/512.256.4/results_thresh_{threshold}/evaluate/randomly_selected_anomaly\"\n",
    "    OUT_DIR_NORMAL  = f\"/scratch/ahmad9/caserm/detect_mse_and_density/model1600/512.256.4/results_thresh_{threshold}/evaluate/randomly_selected_normal\"\n",
    "    csv_path = Path(f\"/scratch/ahmad9/caserm/detect_mse_and_density/model1600/512.256.4/results_thresh_{threshold}/evaluate/sampled_lines.csv\")\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    N     = 500   # how many lines to sample from the merged list\n",
    "    SEED  = 42    # random seed for reproducibility\n",
    "    FILTER_SUBSTR = None  # e.g., \"rank 0\" or \"anomaly\"; use None to skip filtering\n",
    "\n",
    "    # --- Implementation (run as-is) ---\n",
    "    # Example line:\n",
    "    # Rank 0 · line 4, /path/to/file.png: The image is normal\n",
    "    # Regex to pull the PNG path and (optionally) the label\n",
    "    PNG_AND_LABEL = re.compile(r',\\s*(/[^:]+?\\.png):\\s*The image is\\s+(normal|anomaly)\\s*$', re.IGNORECASE)\n",
    "    PNG_IN_LINE   = re.compile(r',\\s*(/[^:]+?\\.png):')\n",
    "\n",
    "    def unique_dest(outdir: Path, src: Path) -> Path:\n",
    "        \"\"\"Return a unique destination path in outdir for src (avoid collisions).\"\"\"\n",
    "        dst = outdir / src.name\n",
    "        if not dst.exists():\n",
    "            return dst\n",
    "        stem, suffix = src.stem, src.suffix\n",
    "        k = 1\n",
    "        while True:\n",
    "            cand = outdir / f\"{stem}_{k}{suffix}\"\n",
    "            if not cand.exists():\n",
    "                return cand\n",
    "            k += 1\n",
    "\n",
    "    # 1) Collect & merge all .txt files\n",
    "    txt_dir = Path(TXT_DIR)\n",
    "    all_txts = sorted(txt_dir.glob(\"*.txt\"))\n",
    "    merged_lines = []\n",
    "    for tf in all_txts:\n",
    "        try:\n",
    "            merged_lines.extend(tf.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines())\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {tf}: {e}\")\n",
    "\n",
    "    if FILTER_SUBSTR:\n",
    "        merged_lines = [ln for ln in merged_lines if FILTER_SUBSTR in ln]\n",
    "\n",
    "    # Keep only lines that look like they contain a PNG path (for sampling)\n",
    "    candidate_lines = [ln for ln in merged_lines if PNG_IN_LINE.search(ln)]\n",
    "    if not candidate_lines:\n",
    "        raise RuntimeError(\"No candidate lines with .png paths were found.\")\n",
    "\n",
    "    # 2) Reproducible sampling of lines\n",
    "    rng = random.Random(SEED)\n",
    "    n = min(N, len(candidate_lines))\n",
    "    sampled_lines = rng.sample(candidate_lines, n)\n",
    "\n",
    "    # Prepare output dirs\n",
    "    out_anom = Path(OUT_DIR_ANOMALY); out_anom.mkdir(parents=True, exist_ok=True)\n",
    "    out_norm = Path(OUT_DIR_NORMAL);  out_norm.mkdir(parents=True, exist_ok=True)\n",
    "    out_all  = Path(OUT_DIR_ALL);     out_all.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 3) Process sampled lines: copy to ALL, then by label\n",
    "    copied_all, copied_anom, copied_norm, missing = [], [], [], []\n",
    "    for ln in sampled_lines:\n",
    "        # Parse path + label (fallback to tail)\n",
    "        m = PNG_AND_LABEL.search(ln)\n",
    "        if m:\n",
    "            png_path = Path(m.group(1))\n",
    "            label = m.group(2).lower().strip()\n",
    "        else:\n",
    "            m2 = PNG_IN_LINE.search(ln)\n",
    "            if not m2:\n",
    "                continue\n",
    "            png_path = Path(m2.group(1))\n",
    "            tail = ln.strip().lower()\n",
    "            if   tail.endswith(\"anomaly\"): label = \"anomaly\"\n",
    "            elif tail.endswith(\"normal\"):  label = \"normal\"\n",
    "            else:                          label = \"\"  # unknown label is fine for ALL\n",
    "\n",
    "        if png_path.exists():\n",
    "            # Copy to ALL\n",
    "            dst_all = unique_dest(out_all, png_path)\n",
    "            shutil.copy2(png_path, dst_all)\n",
    "            copied_all.append((png_path, dst_all))\n",
    "\n",
    "            # Copy by label\n",
    "            if label == \"anomaly\":\n",
    "                dst = unique_dest(out_anom, png_path)\n",
    "                shutil.copy2(png_path, dst)\n",
    "                copied_anom.append((png_path, dst))\n",
    "            elif label == \"normal\":\n",
    "                dst = unique_dest(out_norm, png_path)\n",
    "                shutil.copy2(png_path, dst)\n",
    "                copied_norm.append((png_path, dst))\n",
    "        else:\n",
    "            missing.append(str(png_path))\n",
    "\n",
    "    # Manifests\n",
    "    (out_anom / \"copied_manifest_anomaly.csv\").write_text(\n",
    "        \"src,dst\\n\" + \"\\n\".join(f\"{s},{d}\" for s, d in copied_anom), encoding=\"utf-8\"\n",
    "    )\n",
    "    (out_norm / \"copied_manifest_normal.csv\").write_text(\n",
    "        \"src,dst\\n\" + \"\\n\".join(f\"{s},{d}\" for s, d in copied_norm), encoding=\"utf-8\"\n",
    "    )\n",
    "    # Save the exact sampled lines for traceability\n",
    "    sampled_text = \"\\n\".join(sampled_lines)\n",
    "    (ROOT / \"sampled_lines.txt\").write_text(sampled_text, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "    rows = []\n",
    "    for ln in sampled_lines:\n",
    "        m = PNG_AND_LABEL.search(ln)\n",
    "        if m:\n",
    "            png = m.group(1)\n",
    "            label = m.group(2).lower().strip()\n",
    "        else:\n",
    "            m2 = PNG_IN_LINE.search(ln)\n",
    "            png = m2.group(1) if m2 else \"\"\n",
    "            tail = ln.strip().lower()\n",
    "            label = \"anomaly\" if tail.endswith(\"anomaly\") else \"normal\" if tail.endswith(\"normal\") else \"\"\n",
    "\n",
    "        png_name = Path(png).name if png else \"\"\n",
    "        rows.append((ln, png, label, png_name))\n",
    "\n",
    "    # (Optional) natural sort so numbers in filenames sort as 1,2,10 not 1,10,2\n",
    "    def _nkey(s):  # natural sort key\n",
    "        parts = re.split(r\"(\\d+)\", s or \"\")\n",
    "        return [int(p) if p.isdigit() else p.lower() for p in parts]\n",
    "\n",
    "    rows_sorted = sorted(rows, key=lambda r: _nkey(r[3]))  # sort by png_name\n",
    "\n",
    "    with csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"full_line\", \"png_path\", \"label\", \"png_name\"])\n",
    "        w.writerows(rows_sorted)\n",
    "\n",
    "    print(f\"Wrote sampled-lines CSV → {csv_path} (sorted by png_name)\")\n",
    "\n",
    "    if missing:\n",
    "        (out_anom / \"missing.txt\").write_text(\"\\n\".join(missing), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"Merged {len(all_txts)} .txt files; {len(merged_lines)} lines total \"\n",
    "        f\"({len(candidate_lines)} with PNGs).\")\n",
    "    print(f\"Sampled {n} lines → copied {len(copied_anom)} anomalies, {len(copied_norm)} normals; \"\n",
    "        f\"missing {len(missing)}.\")\n",
    "    print(f\"Anomaly out dir: {out_anom}\")\n",
    "    print(f\"Normal  out dir: {out_norm}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dasanomaly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
